{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = reuters.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = {}\n",
    "for cat in categories:\n",
    "    tops[cat] = len(reuters.fileids(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tops = sorted(tops.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tops = sorted_tops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('earn', 3964),\n",
       " ('acq', 2369),\n",
       " ('money-fx', 717),\n",
       " ('grain', 582),\n",
       " ('crude', 578),\n",
       " ('trade', 485),\n",
       " ('interest', 478),\n",
       " ('ship', 286),\n",
       " ('wheat', 283),\n",
       " ('corn', 237)]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "sorted_tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['test/14859',\n",
       " 'test/14860',\n",
       " 'test/14872',\n",
       " 'test/14873',\n",
       " 'test/14875',\n",
       " 'test/14876',\n",
       " 'test/14899',\n",
       " 'test/14903',\n",
       " 'test/14911',\n",
       " 'test/14926']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "reuters.fileids(sorted_tops[0][0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_courpse(index, percentage=0.05):\n",
    "    corpus = []\n",
    "    mst = reuters.fileids(sorted_tops[index][0])\n",
    "    length = len(mst)\n",
    "    docs = mst[: int(percentage * length)]\n",
    "    for doc in docs:\n",
    "        corpus.append(reuters.words(doc))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_courpse_top_10 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "labels.extend([0]*len(build_courpse(0)))\n",
    "labels.extend([1]*len(build_courpse(1, 0.1)))\n",
    "for ind in range(2, 10):\n",
    "    labels.extend([ind]*len(build_courpse(ind, 0.4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1889"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_courpse_top_10.extend(build_courpse(0))\n",
    "final_courpse_top_10.extend(build_courpse(1, 0.1))\n",
    "for ind in range(2, 10):\n",
    "    final_courpse_top_10.extend(build_courpse(ind, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "words = list(itertools.chain(*final_courpse_top_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_words = list(filter(lambda x: len(x)>=3, words))\n",
    "final_courpse_top_10 = [\" \".join(x) for x in final_courpse_top_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "A = vec.fit_transform(final_courpse_top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1889, 13244)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1889,)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "kmeans.labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(real_labels, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_purity(conf_matrix, real_labels=None):\n",
    "    purity = 0\n",
    "    for i in range(10):\n",
    "        purity += (max(conf_matrix.T[i,:]))/len(real_labels)\n",
    "    print(purity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.19904711487559554\n"
     ]
    }
   ],
   "source": [
    "get_purity(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(conf_matrix, real_labels=None):\n",
    "    import math\n",
    "    entropy = 0\n",
    "    conf_matrix_eps = conf_matrix.T + 1.001\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            entropy += (conf_matrix_eps[i][j] * math.log(conf_matrix_eps[i][j]/sum(conf_matrix_eps[:,i])))\n",
    "    entropy *= -1 * (1/(len(real_labels)* math.log(len(real_labels))))\n",
    "    print(entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.17820159785275794\n"
     ]
    }
   ],
   "source": [
    "get_entropy(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1.747264181571106"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "math.log(conf_matrix_eps[1][1]/(sum(conf_matrix_eps[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10, 13244)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.05625764370158989\n0.09148101634400618\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def build_courpse(index, percentage=0.05):\n",
    "    corpus = []\n",
    "    mst = reuters.fileids(sorted_tops[index][0])\n",
    "    length = len(mst)\n",
    "    docs = mst[: int(percentage * length)]\n",
    "    for doc in docs:\n",
    "        corpus.append(reuters.words(doc))\n",
    "    return corpus\n",
    "sorted_tops = sorted(tops.items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_tops = sorted_tops[:20]\n",
    "final_courpse_top_20 = []\n",
    "labels_20 = []\n",
    "labels_20.extend([0]*len(build_courpse(0)))\n",
    "labels_20.extend([1]*len(build_courpse(1, 0.1)))\n",
    "for ind in range(2, 20):\n",
    "    labels_20.extend([ind]*len(build_courpse(ind, 0.4)))\n",
    "real_labels = np.array(labels_20)\n",
    "for ind in range(2, 20):\n",
    "    labels_20.extend([ind]*len(build_courpse(ind, 0.4)))\n",
    "final_courpse_top_20.extend(build_courpse(0))\n",
    "final_courpse_top_20.extend(build_courpse(1, 0.1))\n",
    "for ind in range(2, 20):\n",
    "    final_courpse_top_20.extend(build_courpse(ind, 0.4))\n",
    "final_courpse_top_20 = [\" \".join(x) for x in final_courpse_top_20]\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "A = vec.fit_transform(final_courpse_top_20)\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=20, random_state=0).fit(A)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(real_labels, kmeans.labels_)\n",
    "get_purity(conf_matrix)\n",
    "get_entropy(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.12922951487973908\n0.1174786073578191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=20, init='random', random_state=0)\n",
    "W = model.fit_transform(A)\n",
    "H = model.components_\n",
    "conf_matrix = confusion_matrix(real_labels, np.argmax(W, axis=1))\n",
    "get_purity(conf_matrix)\n",
    "get_entropy(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TDT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/seyed/Downloads/TDT2_all.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, labels = mat[\"fea\"], mat[\"gnd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10212,)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "labels.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.03466509988249119\n0.012642627126321452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=96, random_state=0).fit(A)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(labels.ravel(), kmeans.labels_)\n",
    "get_purity(conf_matrix, labels.ravel())\n",
    "get_entropy(conf_matrix, labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "len(set(labels.ravel().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_label = pd.DataFrame({\"label\":labels.ravel()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_10 = df_label.groupby(\"label\").size()[::-1][:10].index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = df_label.groupby(\"label\").size()[:10].index.to_numpy()\n",
    "top_10_val = df_label.groupby(\"label\").size()[:10].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint64)"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = ll.tolist()\n",
    "index_top_10 = []\n",
    "index_last_10 = []\n",
    "for i, a in enumerate(l1):\n",
    "    if a in top_10:\n",
    "        index_top_10.append(i)\n",
    "for i, a in enumerate(l1):\n",
    "    if a in last_10:\n",
    "        index_last_10.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[10201, 10202, 10203, 10204, 10205, 10206, 10207, 10208, 10209, 10210, 10211]"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "index_last_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_arr = A.toarray()\n",
    "top_A , top_labels = np.zeros((len(index_top_10), A_arr.shape[1])), []\n",
    "for i, j in enumerate(index_top_10):\n",
    "    top_A[i,:] = A_arr[j,:]\n",
    "    top_labels.append(ll[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_labels = np.array(top_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_A , last_labels = np.zeros((len(index_last_10), A_arr.shape[1])), []\n",
    "for i, j in enumerate(index_last_10):\n",
    "    last_A[i,:] = A_arr[j,:]\n",
    "    last_labels.append(ll[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_labels = np.array(last_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((11, 36771), (11,))"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "last_A.shape, last_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5021459227467812\n-0.05216949623920224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(top_A)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(top_labels, kmeans.labels_)\n",
    "get_purity(conf_matrix, top_labels)\n",
    "get_entropy(conf_matrix, top_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8130364806866953\n0.017263215343055787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=10, init='random', random_state=0)\n",
    "W = model.fit_transform(top_A)\n",
    "H = model.components_\n",
    "conf_matrix = confusion_matrix(top_labels, np.argmax(W, axis=1))\n",
    "get_purity(conf_matrix, top_labels)\n",
    "get_entropy(conf_matrix, top_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9090909090909093\n",
      "11.368788286373869\n",
      "0.9090909090909093\n",
      "11.310417628880485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(last_A)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(last_labels, kmeans.labels_)\n",
    "get_purity(conf_matrix, last_labels)\n",
    "get_entropy(conf_matrix, last_labels)\n",
    "#-----------------------------------------------------------------\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=10, init='random', random_state=0)\n",
    "W = model.fit_transform(last_A)\n",
    "H = model.components_\n",
    "conf_matrix = confusion_matrix(last_labels, np.argmax(W, axis=1))\n",
    "get_purity(conf_matrix, last_labels)\n",
    "get_entropy(conf_matrix, last_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_20 = df_label.groupby(\"label\").size()[::-1][:20].index.to_numpy()\n",
    "top_20 = df_label.groupby(\"label\").size()[:20].index.to_numpy()\n",
    "\n",
    "index_top_20 = []\n",
    "index_last_20 = []\n",
    "for i, a in enumerate(l1):\n",
    "    if a in top_20:\n",
    "        index_top_20.append(i)\n",
    "\n",
    "for i, a in enumerate(l1):\n",
    "    if a in last_20:\n",
    "        index_last_20.append(i)\n",
    "\n",
    "top_A_20 , top_labels_20 = np.zeros((len(index_top_20), A_arr.shape[1])), []\n",
    "for i, j in enumerate(index_top_20):\n",
    "    top_A_20[i,:] = A_arr[j,:]\n",
    "    top_labels_20.append(ll[j])\n",
    "\n",
    "top_labels_20 = np.array(top_labels_20)\n",
    "\n",
    "last_A_20 , last_labels_20 = np.zeros((len(index_last_20), A_arr.shape[1])), []\n",
    "for i, j in enumerate(index_last_20):\n",
    "    last_A_20[i,:] = A_arr[j,:]\n",
    "    last_labels_20.append(ll[j])\n",
    "last_labels_20 = np.array(last_labels_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((42, 36771), (42,), (8741, 36771), (8741,))"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "last_A_20.shape, last_labels_20.shape, top_A_20.shape , top_labels_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(top_A_20)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(top_labels_20, kmeans.labels_)\n",
    "get_purity(conf_matrix, top_labels_20)\n",
    "get_entropy(conf_matrix, top_labels_20)\n",
    "#-----------------------------------------------------------------\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=10, init='random', random_state=0)\n",
    "W = model.fit_transform(top_A_20)\n",
    "H = model.components_\n",
    "conf_matrix = confusion_matrix(top_labels_20, np.argmax(W, axis=1))\n",
    "get_purity(conf_matrix, top_labels_20)\n",
    "get_entropy(conf_matrix, top_labels_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(last_A_20)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(last_labels_20, kmeans.labels_)\n",
    "get_purity(conf_matrix, last_labels_20)\n",
    "get_entropy(conf_matrix, last_labels_20)\n",
    "#-----------------------------------------------------------------\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=10, init='random', random_state=0)\n",
    "W = model.fit_transform(last_A_20)\n",
    "H = model.components_\n",
    "conf_matrix = confusion_matrix(last_labels_20, np.argmax(W, axis=1))\n",
    "get_purity(conf_matrix, last_labels_20)\n",
    "get_entropy(conf_matrix, last_labels_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}